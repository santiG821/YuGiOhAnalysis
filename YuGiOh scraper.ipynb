{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Define base file name\n",
    "base_file_name = \"C:/Users/santi/Desktop/TCG/TCGplayer_ Shop YuGiOh Cards, Packs, Booster Boxes\"\n",
    "\n",
    "# Create and open the CSV file\n",
    "with open('card_data.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['Card Name', 'Rarity', 'Number', 'Price', 'Market Price', 'Listing Count'])\n",
    "\n",
    "    # Iterate over each file\n",
    "    for i in range(1, 41):  # Adjust the range based on how many files you have\n",
    "        file_name = base_file_name + str(i) + \".html\"\n",
    "\n",
    "        # Open the HTML file\n",
    "        with open(file_name, 'r', encoding='utf-8') as html_file:\n",
    "            html = html_file.read()\n",
    "\n",
    "        # Create a BeautifulSoup object\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Find all 'section' tags with class 'search-result__product'\n",
    "        card_sections = soup.find_all('section', {'class': 'search-result__product'})\n",
    "\n",
    "        # Iterate over each card section\n",
    "        for card in card_sections:\n",
    "\n",
    "            # Extract the card name\n",
    "            card_name_tag = card.find('span', {'class': 'search-result__title'})\n",
    "            card_name = card_name_tag.text if card_name_tag else ''\n",
    "\n",
    "            # Extract the rarity and number\n",
    "            rarity_section = card.find('section', {'class': 'search-result__rarity'})\n",
    "            if rarity_section:\n",
    "                rarity_spans = rarity_section.find_all('span')\n",
    "                if len(rarity_spans) >= 3:\n",
    "                    rarity = rarity_spans[0].text\n",
    "                    number = rarity_spans[2].text\n",
    "            else:\n",
    "                rarity = ''\n",
    "                number = ''\n",
    "\n",
    "            # Extract the price\n",
    "            price_tag = card.find('span', {'class': 'inventory__price-with-shipping'})\n",
    "            price = price_tag.text if price_tag else ''\n",
    "\n",
    "            listing_container = card.find('div', {'class': 'inventory__container'})\n",
    "            if listing_container:\n",
    "                listing_count_tag = listing_container.find('span', {'class': 'inventory__listing-count'})\n",
    "                if listing_count_tag:\n",
    "                    listing_count_text = listing_count_tag.text\n",
    "                    listing_count = int(listing_count_text.split()[0])\n",
    "                else:\n",
    "                    listing_count = ''\n",
    "            market_price = soup.find('span', class_='search-result__market-price--value').text\n",
    "            # Write the card data to the CSV file\n",
    "            writer.writerow([card_name, rarity, number, price, market_price, listing_count])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Read your CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"C:/Users/santi/Desktop/VSCODEWORKING/card_data.csv\")\n",
    "card_list = df['Card Name'].tolist()\n",
    "\n",
    "# Prepare to count mentions\n",
    "mentions = defaultdict(int, {card: 0 for card in card_list})\n",
    "\n",
    "\n",
    "# Create a Reddit instance\n",
    "reddit = praw.Reddit(\n",
    "    client_id='Cmr3W3e6ewCr728I1DgZ9Q',\n",
    "    client_secret='jxbtT-nxuvriUNJTOa2WEij0GZM1Eg',\n",
    "    user_agent='yugioh card counter V1',\n",
    "    username='sneeze820',\n",
    "    password='Santi8/21/06',\n",
    ")\n",
    "\n",
    "# Set your subreddit\n",
    "subreddit = reddit.subreddit('yugioh')\n",
    "\n",
    "# Loop through each post in the subreddit\n",
    "for post in subreddit.new(limit=1000):\n",
    "    # Check each card in the card list\n",
    "    for card in card_list:\n",
    "        # If the card name is in the post title or content, increment the count\n",
    "        if card.lower() in post.title.lower() or card.lower() in post.selftext.lower():\n",
    "            mentions[card] += 1\n",
    "\n",
    "# Print the results\n",
    "# Add a new column to the DataFrame for the mention counts\n",
    "df['Mention Count'] = df['Card Name'].map(mentions)\n",
    "\n",
    "# Write the DataFrame back to the CSV file\n",
    "df.to_csv('C:/Users/santi/Desktop/VSCODEWORKING/card_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\santi\\Desktop\\VSCODEWORKING\n"
     ]
    }
   ],
   "source": [
    "new_directory = \"C:/Users/santi/Desktop/VSCODEWORKING\"\n",
    "\n",
    "# Change the working directory\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Check the new working directory\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
